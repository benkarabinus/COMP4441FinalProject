sqrt(2)
(mu-1)
mean(((meansamples2<qnorm(0.005,mu-1,sig/sqrt(50)))+
(meansamples2>qnorm(0.995,mu-1,sig/sqrt(50))))>0)
dat.plot<-data.frame(x=c(0,3*mu))
ggplot(data=dat.plot,aes(x=x))+
stat_function(fun=dgamma, args=list(shape=shp,scale=scl))
ggqqplot(rgamma(100,shp,scl))
samples2<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples2<-colMeans(samples2)
mean(samples2)
sqrt(2)
(mu-1)
mean(((meansamples2<qnorm(0.005,mu-1,sig/sqrt(50)))+
(meansamples2>qnorm(0.995,mu-1,sig/sqrt(50))))>0)
set.seed(123456)
z.p.val.round.true<-function(a=shp,s=scl){
samp<-round(rnorm(n,mu,sig),1)
return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
}
ps.round.true<-replicate(100000,z.p.val.round.true())
mean(ps.round.true<.01)
z.p.val.true<-function(a=shp,s=scl){
samp<-rgamma(n,shape=a,scale=s)
return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
}
set.seed(1234567)
ps.true<-replicate(100000,z.p.val.true())
mean(ps.true<.05)
set.seed(123456)
samples2<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples2<-colMeans(samples2)
mean(samples2)
sqrt(2)
(mu)
mean(((meansamples2<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples2>qnorm(0.995,mu,sig/sqrt(50))))>0)
# z.p.val.round.true<-function(a=shp,s=scl){
#   samp<-round(rnorm(n,mu,sig),1)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
#
# ps.round.true<-replicate(100000,z.p.val.round.true())
# mean(ps.round.true<.01)
set.seed(123456)
samples4<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples4<-colMeans(samples4)
mean(((meansamples4<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples4>qnorm(0.995,mu,sig/sqrt(50))))>0)
# z.p.val.round.true<-function(a=shp,s=scl){
#   samp<-round(rnorm(n,mu,sig),1)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
#
# ps.round.true<-replicate(100000,z.p.val.round.true())
# mean(ps.round.true<.01)
# z.p.val.true<-function(a=shp,s=scl){
#   samp<-rgamma(n,shape=a,scale=s)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
# set.seed(1234567)
# ps.true<-replicate(100000,z.p.val.true())
# mean(ps.true<.05)
samples4<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples4<-colMeans(samples4)
mean(((meansamples4<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples4>qnorm(0.995,mu,sig/sqrt(50))))>0)
n<-50
set.seed(1234567)
ggqqplot(round(rnorm(n,mu,sig),1))
samples3<-sapply(1:1e5, function(a) round(rnorm(50,mu,sig),1))
meansamples3<-colMeans(samples3)
mean(((meansamples3<qnorm(0.005,mu-1,sig/sqrt(50)))+
(meansamples3>qnorm(0.995,mu-1,sig/sqrt(50))))>0)
set.seed(123456)
samples5=sapply(1:1e5, function(a) round(rnorm(50,mu,sig),1))
meansamples5=colMeans(samples5)
mean(((meansamples5<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples5>qnorm(0.995,mu,sig/sqrt(50))))>0)
# z.p.val.round.true<-function(a=shp,s=scl){
#   samp<-round(rnorm(n,mu,sig),1)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
#
# ps.round.true<-replicate(100000,z.p.val.round.true())
# mean(ps.round.true<.01)
# z.p.val.true<-function(a=shp,s=scl){
#   samp<-rgamma(n,shape=a,scale=s)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
# set.seed(1234567)
# ps.true<-replicate(100000,z.p.val.true())
# mean(ps.true<.05)
samples4<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples4<-colMeans(samples4)
mean(((meansamples4<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples4>qnorm(0.995,mu,sig/sqrt(50))))>0)
mu
# z.p.val.true<-function(a=shp,s=scl){
#   samp<-rgamma(n,shape=a,scale=s)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
# set.seed(1234567)
# ps.true<-replicate(100000,z.p.val.true())
# mean(ps.true<.05)
samples4<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples4<-colMeans(samples4)
mean(((meansamples4<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples4>qnorm(0.995,mu,sig/sqrt(50))))>0)
set.seed(123456)
samples5=sapply(1:1e5, function(a) round(rnorm(50,mu,sig),1))
meansamples5=colMeans(samples5)
mean(((meansamples5<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples5>qnorm(0.995,mu,sig/sqrt(50))))>0)
# z.p.val.round.true<-function(a=shp,s=scl){
#   samp<-round(rnorm(n,mu,sig),1)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
#
# ps.round.true<-replicate(100000,z.p.val.round.true())
# mean(ps.round.true<.01)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggpubr)
library(AER)# for the data
library(ggpubr)
data("USSeatBelts")
table(USSeatBelts$year,USSeatBelts$drinkage)
dat<-USSeatBelts
dat<-pivot_wider(dat,id_cols=state,names_from = year,values_from = c(fatalities,drinkage))
dat$drinkage_1983=="no"
fatal.diff<-dat$fatalities_1983[dat$drinkage_1983=="no"]-
dat$fatalities_1988[dat$drinkage_1983=="no"]
ggqqplot(fatal.diff)
t.test(dat$fatalities_1988[dat$drinkage_1988=="yes"],
dat$fatalities_1983[dat$drinkage_1983=="no"])
t.test(dat$fatalities_1988[dat$drinkage_1988=="yes"],
dat$fatalities_1983[dat$drinkage_1983=="no"],
conf.level = .99)
fatal.diff.yes<-dat$fatalities_1983[dat$drinkage_1983=="yes"]-
dat$fatalities_1988[dat$drinkage_1983=="yes"]
mean(fatal.diff.yes)
fatal.diff.no<-dat$fatalities_1983[dat$drinkage_1983=="no"]-
dat$fatalities_1988[dat$drinkage_1983=="no"]
mean(fatal.diff.no)
t.test(dat$fatalities_1988[dat$drinkage_1988=="yes"],
dat$fatalities_1983[dat$drinkage_1983=="yes"])
set.seed(12345)
shp<-2
scl<-sqrt(4/shp)
sig<-sqrt(shp*scl^2) # sigma in 2a
mu<-shp*scl # 2*sqrt(2), mu in 2a
qs=qnorm(c(0.05,0.995),mu-1,sig/sqrt(50))
pnorm(qs[1],mu,sig/sqrt(50))+pnorm(qs[2],mu,sig/sqrt(50),
lower.tail = F)
samples=sapply(1:1e5, function(a) rnorm(50,mu,sig))
meansamples=colMeans(samples)
mean(((meansamples<qnorm(0.005,mu-1,sig/sqrt(50)))+
(meansamples>qnorm(0.995,mu-1,sig/sqrt(50))))>0)
dat.plot<-data.frame(x=c(0,3*mu))
ggplot(data=dat.plot,aes(x=x))+
stat_function(fun=dgamma, args=list(shape=shp,scale=scl))
ggqqplot(rgamma(100,shp,scl))
samples2<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples2<-colMeans(samples2)
mean(samples2)
sqrt(2)
(mu-1)
mean(((meansamples2<qnorm(0.005,mu-1,sig/sqrt(50)))+
(meansamples2>qnorm(0.995,mu-1,sig/sqrt(50))))>0)
n<-50
set.seed(1234567)
ggqqplot(round(rnorm(n,mu,sig),1))
samples3<-sapply(1:1e5, function(a) round(rnorm(50,mu,sig),1))
meansamples3<-colMeans(samples3)
mean(((meansamples3<qnorm(0.005,mu-1,sig/sqrt(50)))+
(meansamples3>qnorm(0.995,mu-1,sig/sqrt(50))))>0)
samples4<-sapply(1:1e5, function(a) rgamma(50,shp,scl))
meansamples4<-colMeans(samples4)
mean(((meansamples4<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples4>qnorm(0.995,mu,sig/sqrt(50))))>0)
set.seed(123456)
samples5=sapply(1:1e5, function(a) round(rnorm(50,mu,sig),1))
meansamples5=colMeans(samples5)
mean(((meansamples5<qnorm(0.005,mu,sig/sqrt(50)))+
(meansamples5>qnorm(0.995,mu,sig/sqrt(50))))>0)
# z.p.val.round.true<-function(a=shp,s=scl){
#   samp<-round(rnorm(n,mu,sig),1)
#   return(2*pnorm(-abs((mean(samp)-mu)/(sig/sqrt(n)))))
# }
#
# ps.round.true<-replicate(100000,z.p.val.round.true())
# mean(ps.round.true<.01)
library(tidyverse)
library(ggplot2)
library(HistData)
data("PolioTrials")
dat<-PolioTrials
m<-as.matrix(dat[1:2,3:4],nrow=2)
m[,1]<-m[,1]-m[,2]
chisq.test(m)
chisq.test(m, correct=FALSE)
dimnames(m)[[1]]<-c("treatment", "control")
dimnames(m)[[2]]<-c("no polio","polio")
m
model.chisq<-chisq.test(m)
model.chisq$expected
p<-sum(m[,2])/sum(m)
(P<-matrix(c(1-p,p),ncol=2))
(T<-matrix(rowSums(m),nrow=2))
(E<-T%*%P)
# check
rowSums(E)
rowSums(m)
colSums(E)
colSums(m)
(chistat<-sum((m-E)^2/E))
(chistat_adj<-sum((abs(m-E)-.5)^2/E))
x=seq(0,20,by=.1)
dat<-bind_rows(data.frame(x=x,y=dchisq(x,1),deg=1),
data.frame(x=x,y=dchisq(x,5),deg=5),
data.frame(x=x,y=dchisq(x,10),deg=10)
)
ggplot(group_by(dat,deg),aes(x=x,y=y,color=factor(deg)))+geom_line()
pchisq(chistat,df=1,lower.tail=FALSE)
chisq.test(m, correct=FALSE)
pchisq(chistat_adj,df=1,lower.tail=FALSE)
chisq.test(m)
dat<-PolioTrials
#initial setup
if(!require(DataExplorer)){install.packages("DataExplorer")}
library(DataExplorer)
if(!require(tidyr)){install.packages("tidyr")}
library(tidyr)
# Load Datasets
# Albequerque
ABQ <- read.csv("ABQ.csv", header = T)
#initial setup
if(!require(DataExplorer)){install.packages("DataExplorer")}
library(DataExplorer)
if(!require(tidyr)){install.packages("tidyr")}
library(tidyr)
# Load Datasets
# Albequerque
ABQ <- read.csv("ABQ.csv", header = T)
# Load Datasets
# Albequerque
ABQ <- read.csv("ABQ.csv")
# Load Datasets
# Albequerque
ABQ <- read.csv("ABQ.csv", header = T)
#initial setup
if(!require(DataExplorer)){install.packages("DataExplorer")}
library(DataExplorer)
if(!require(tidyr)){install.packages("tidyr")}
library(tidyr)
# Load Datasets
# Albequerque
ABQ <- read.csv("ABQ.csv", header = T)
arima<-sarima(abq_ts)
pred <- forecast(arima, h=50)
plot(pred)
#initial setup
library(DataExplorer)
library(tidyverse)
library(lubridate)
library(tseries)
library(forecast)
library(ggplot2)
library(dplyr)
library(TTR)
library(fpp2)
library(reader)
library(stats)
setwd("/home/ellmann/Documents/stats/COMP4441FinalProject")
ABQ <- read.csv("ABQ.csv", header = T)
DEN <- read.csv("DEN.csv", header = T)
PHX <- read.csv("PHX.csv", header = T)
SLC <- read.csv("SLC.csv", header = T)
# replace NA's in the SNOW column with the median snowfall
ABQ$SNOW[is.na(ABQ$SNOW)] <- median(ABQ$SNOW, na.rm = T)
DEN$SNOW[is.na(DEN$SNOW)] <- median(DEN$SNOW, na.rm = T)
PHX$SNOW[is.na(ABQ$SNOW)] <- median(PHX$SNOW, na.rm = T)
SLC$SNOW[is.na(ABQ$SNOW)] <- median(SLC$SNOW, na.rm = T)
# replace the missing values for TAVG, values replaced by the average of TMAX and TMIN
TEMP <- data.frame(ABQ$TMAX, ABQ$TMIN)
ind <- which(is.na(ABQ), arr.ind=TRUE)
ABQ[ind] <- round(rowMeans(TEMP, na.rm=TRUE)[ind[,1]],0)
profile_missing(ABQ)
TEMP <- data.frame(DEN$TMAX, DEN$TMIN)
ind <- which(is.na(DEN), arr.ind=TRUE)
DEN[ind] <- round(rowMeans(TEMP, na.rm=TRUE)[ind[,1]],0)
profile_missing(DEN)
TEMP <- data.frame(PHX$TMAX, PHX$TMIN)
ind <- which(is.na(PHX), arr.ind=TRUE)
PHX[ind] <- round(rowMeans(TEMP, na.rm=TRUE)[ind[,1]],0)
profile_missing(PHX)
TEMP <- data.frame(SLC$TMAX, SLC$TMIN)
ind <- which(is.na(SLC), arr.ind=TRUE)
SLC[ind] <- round(rowMeans(TEMP, na.rm=TRUE)[ind[,1]],0)
profile_missing(SLC)
glimpse(ABQ)
# transform DATE column to date data type
ABQ <- transform(ABQ, DATE = as.Date(DATE))
DEN <- transform(DEN, DATE = as.Date(DATE))
PHX <- transform(PHX, DATE = as.Date(DATE))
SLC <- transform(SLC, DATE = as.Date(DATE))
# create column month year to aggregate data for time series
ABQ$MONTH_YEAR <- floor_date(ABQ$DATE,"month")
ABQ$YEAR <- floor_date(ABQ$DATE,"year")
ABQ_AGG <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=mean((TAVG))) %>%
as.data.frame()
ABQ_AGG <- ABQ %>%
group_by(YEAR)%>%
dplyr::summarize(value=mean(TAVG)) %>%
as.data.frame()
abq_ts <- ts(ABQ_AGG[, 2], start= c(1970,1), end= c(2019,12), frequency = 12)
abq_ts
plot(diff(log(ABQ_AGG$value)))
summary(abq_ts)
start(abq_ts)
end(abq_ts)
frequency(abq_ts)
plot(abq_ts)
linearModel = lm(abq_ts ~ time(abq_ts))
abline(reg = linearModel) # fit in a Linear Model (Intercept & Slope), and plot the line
plot(abq_ts)
arima<-sarima(abq_ts)
pred <- forecast(arima, h=50)
plot(pred)
summary(arima)
arima<-auto.arima(abq_ts)
pred <- forecast(arima, h=50)
plot(pred)
ABQ_AGG <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=sum(PRCP)) %>%
as.data.frame()
ABQ_AGG_SNOW <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=sum(SNOW)) %>%
as.data.frame()
View(ABQ_AGG_SNOW)
ABQ_AGG_PRCP <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=sum(PRCP)) %>%
as.data.frame()
View(ABQ_AGG_PRCP)
ABQ_TS_PRCP <- ts(ABQ_AGG_PRCP[, 2], start= c(1970,1), end= c(2019,12), frequency = 12)
ABQ_AGG_TAVG <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=mean(TAVG)) %>%
as.data.frame()
View(ABQ_AGG_TAVG)
ABQ_TS_PRCP <- ts(ABQ_AGG_PRCP[, 2], start= c(1970,1), end= c(2019,12), frequency = 12)
ABQ_TS_PRCP
plot(ABQ_TS_PRCP)
dim(ABQ_TS_PRCP)
View(ABQ_AGG_PRCP)
View(DEN)
ABQ_AGG_PRCP <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=mean(PRCP)) %>%
as.data.frame()
ABQ_TS_PRCP <- ts(ABQ_AGG_PRCP[, 2], start= c(1970,1), end= c(2019,12), frequency = 12)
plot(ABQ_TS_PRCP)
plot(diff(log(ABQ_AGG$value)))
plot(ABQ_TS_PRCP)
#initial setup
if(!require(DataExplorer)){install.packages("DataExplorer")}
library(DataExplorer)
if(!require(tidyverse)){install.packages("tidyverse")}
library(tidyverse)
# Load Datasets
# Albuquerque
ABQ <- read.csv("ABQ.csv", header = T)
# Denver
DEN <- read.csv("DEN.csv", header = T)
# Phoenix
PHX <- read.csv("PHX.csv", header = T)
# Salt Lake City
SLC <- read.csv("SLC.csv", header = T)
# ABQ
summary(ABQ)
# show data types, factors and levels (note that date has been read in as a factor)
str(ABQ)
#view the first few rows of data
head(ABQ)
# visualization to check for missing data
plot_intro(ABQ, title='Albequerque')
# if data missing get the details
profile_missing(ABQ)
# plot of the missing data
plot_missing(ABQ, title = "Albequerque", group=c("No Missing Values"=0,
"PCT Missing Values"= 1))
View(ABQ)
# replace NA's in the SNOW column with the median snowfall
ABQ$SNOW[is.na(ABQ$SNOW)] <- median(ABQ$SNOW, na.rm = T) ### depende
#check to ensure replacement
profile_missing(ABQ)
#check to ensure replacement
profile_missing(ABQ)
# replace the missing values for TAVG, values replaced by the average of TMAX and TMIN
ABQTEMP <- data.frame(ABQ$TMAX, ABQ$TMIN)
ind <- which(is.na(ABQ), arr.ind=TRUE)
# all temperatures are given as whole numbers in dataset so round the mean
ABQ[ind] <- round(rowMeans(ABQTEMP, na.rm=TRUE)[ind[,1]],0)
#check to ensure replacement
profile_missing(ABQ)
# transform DATE column to date data type
ABQ <- transform(ABQ, DATE = as.Date(DATE))
#verify changes
sapply(ABQ, class)
# create column month year to aggregate data for time series
ABQ$MONTH_YEAR <- floor_date(ABQ$DATE,"month")
# create aggregated dataset using MONTH_YEAR COLUMN from ABQ
# This aggeregate will be used to create the time series
ABQ_AGG <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=mean(PRCP)) %>%
as.data.frame()
# create a time series from ABQ_AGG
ABQ_TS <- ts(ABQ_AGG[, 2], start= c(1970,1), end= c(2019,12), frequency = 12)
# basic plot of the new time series
plot(ABQ_TS)
# basic plot of the new time series
plot(ABQ_TS[1:36])
# basic plot of the new time series
plot(ABQ_TS[1:36], type="l")
# create a time series from ABQ_AGG
ABQ_TS <- ts(ABQ_AGG[, 2], start= c(1970,1), end= c(1972,12), frequency = 12)
# create a time series from ABQ_AGG
ABQ_TS <- ts(ABQ_AGG[, 2][1:36], start= c(1970,1), end= c(1972,12), frequency = 12)
# print the new time series
ABQ_TS
# basic plot of the new time series
plot(ABQ_TS)
View(ABQ_AGG)
# create a time series from ABQ_AGG
ABQ_TS <- ts(ABQ_AGG[, 2][1:36], start= c(1970,1), end= c(1972,12), frequency = 1)
# basic plot of the new time series
plot(ABQ_TS)
# create a time series from ABQ_AGG
ABQ_TS <- ts(ABQ_AGG[, 2][1:36], start= c(1970,1), end= c(1972,12), frequency = 12)
# print the new time series
ABQ_TS
# basic plot of the new time series
plot(ABQ_TS)
# print the new time series
ABQ_TS
# create a time series from ABQ_AGG
ABQ_TS <- ts(ABQ_AGG[, 2], start= c(1970,1), end= c(2019,12), frequency = 12)
# print the new time series
ABQ_TS
# basic plot of the new time series
plot(ABQ_TS)
library(forecast)
#initial setup
if(!require(DataExplorer)){install.packages("DataExplorer")}
library(DataExplorer)
if(!require(tidyverse)){install.packages("tidyverse")}
library(tidyverse)
# Load Datasets
# Albuquerque
ABQ <- read.csv("ABQ.csv", header = T)
# if data missing get the details
profile_missing(ABQ)
# replace NA's in the SNOW column with the median snowfall
ABQ$SNOW[is.na(ABQ$SNOW)] <- median(ABQ$SNOW, na.rm = T)
#check to ensure replacement
profile_missing(ABQ)
# replace the missing values for TAVG, values replaced by the average of TMAX and TMIN
ABQTEMP <- data.frame(ABQ$TMAX, ABQ$TMIN)
ind <- which(is.na(ABQ), arr.ind=TRUE)
# all temperatures are given as whole numbers in dataset so round the mean
ABQ[ind] <- round(rowMeans(ABQTEMP, na.rm=TRUE)[ind[,1]],0)
#check to ensure replacement
profile_missing(ABQ)
# transform DATE column to date data type
ABQ <- transform(ABQ, DATE = as.Date(DATE))
A
# create aggregated dataset using MONTH_YEAR COLUMN from ABQ
# This aggeregate will be used to create the time series
ABQ_AGG <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=sum(PRCP)) %>%
as.data.frame()
# create column month year to aggregate data for time series
ABQ$MONTH_YEAR <- floor_date(ABQ$DATE,"month")
# create aggregated dataset using MONTH_YEAR COLUMN from ABQ
# This aggeregate will be used to create the time series
ABQ_AGG <- ABQ %>%
group_by(MONTH_YEAR)%>%
dplyr::summarize(value=sum(PRCP)) %>%
as.data.frame()
# create a time series from ABQ_AGG
ABQ_TS <- ts(ABQ_AGG[, 2], start= c(1970,1), end= c(2019,12), frequency = 12)
# basic plot of the new time series
plot(ABQ_TS)
library(tseries)
adf.test(ABQ_TS,alternative = "stationary")
modelo=auto.arima(ABQ_TS)
modelo
plot(forecast(modelo,h=60),xlim=c(2010,2024))
a=forecast(modelo,h=60)
a
a$lower
adf.test(ABQ_TS,alternative = "stationary")
gc()
gc()
